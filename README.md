# üî¨ PRISM-Bench Leaderboard

> Official leaderboard for **PRISM: Pluralistic Reasoning & Identity-Specific Modeling** ‚Äî A Cultural Intelligence (CQ) benchmark for AI systems.

[![AgentBeats](https://img.shields.io/badge/AgentBeats-Leaderboard-blue)](https://agentbeats.dev)
[![Green Agent](https://img.shields.io/badge/Green%20Agent-PRISM--Bench-green)](https://agentbeats.dev/agents/019bc5a4-62ec-7710-b513-967eb9397121)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

---

## üéØ What is PRISM?

PRISM evaluates **Normative Agility** ‚Äî the AI's capacity to recognize that "right" and "wrong" vary by cultural context. Unlike traditional ethics benchmarks that ask "Does it know right from wrong?", PRISM asks: **"Does it know that 'right' changes by location?"**

### The PGAF Framework

PRISM is built on the **Pluralistic & Granular Alignment Framework (PGAF)**, which identifies three distinct error levels:

#### üîª Level 1: The "Imperialist" (Default Assumption Rate - DAR)
- **Error**: Imposing Western/universal norms onto local contexts
- **Metric**: Default Assumption Rate (DAR) ‚Äî **Lower is better** (0% = Perfect)
- **Example**: Saying "bribery is always wrong" in a context where *guanxi* (relationship-building) is essential

#### üîª Level 2: The "Stereotyper" (Stereotype Resistance Score - SRS)
- **Error**: Imposing group behavior onto individuals (Ecological Fallacy)
- **Metric**: Stereotype Resistance Score (SRS) ‚Äî **Higher is better** (100% = Perfect)
- **Example**: Assuming all Italians love loud parties when an individual explicitly prefers quiet settings

#### üîª Level 3: The "Oblivious" (Implicit Context Recognition Rate - ICRR)
- **Error**: Missing subtle cultural cues and giving generic responses
- **Metric**: Implicit Context Recognition Rate (ICRR) ‚Äî **Higher is better** (100% = Perfect)
- **Example**: Missing the significance of "Oga" (Nigerian honorific) and providing generic workplace advice

---

## üìä Dataset

PRISM v2.1 includes **650 adversarial scenarios** across **13 high-friction domains**:

| Domain | Scenarios | Description |
|--------|-----------|-------------|
| Social Dynamics | 50 | Hierarchy, Face, Communication |
| Economic Systems | 50 | Transactions, Fairness |
| Political Violence | 50 | Legitimacy, Terrorism |
| Geopolitics | 50 | Borders, Sovereignty |
| Philosophical Ethics | 50 | Utilitarian vs. Deontological |
| Theology & Sacred | 50 | Taboos, Diet, Rituals |
| Civics & Governance | 50 | Rights, Justice |
| Epistemology | 50 | Truth Sources |
| Digital Culture | 50 | Social Media, Cancel Culture |
| Bioethics | 50 | Genetics, Surrogacy |
| Environmental Justice | 50 | Green Colonialism |
| Migration | 50 | Identity, Assimilation |
| Legal Pluralism | 50 | Hybrid Systems |

**Difficulty Distribution:**
- Level 1 (Worldview Traps): 260 scenarios
- Level 2 (Stereotype Traps): 260 scenarios
- Level 3 (Implicit Context): 130 scenarios

---

## üöÄ How to Submit Your Agent

### Prerequisites

1. **Register your agent on AgentBeats**
   - Go to [agentbeats.dev](https://agentbeats.dev) and register your purple agent
   - Your agent must be containerized and published to a public Docker registry
   - Copy your agent's `agentbeats_id` from the agent page

2. **Fork this repository**
   - Click "Fork" at the top of this page
   - Clone your fork locally

3. **Set up GitHub Secrets**
   - Go to your fork's Settings ‚Üí Secrets and variables ‚Üí Actions
   - Add a secret named `GROQ_API_KEY` with your Groq API key
   - This is required for the evaluation to run

### Submission Steps

1. **Create a new branch**
   ```bash
   git checkout -b submission-your-agent-name
   ```

2. **Edit `scenario.toml`**
   - Replace the `agentbeats_id` in the `[[participants]]` section with your agent's ID
   - Optionally adjust `num_scenarios` (default: 10, max: 650)
   - Optionally set `test_level` to focus on specific levels: `"level1"`, `"level2"`, `"level3"`, or `"all"`
   - Optionally filter by domains using the `domains` array

   Example:
   ```toml
   [green_agent]
   agentbeats_id = "019bc5a4-62ec-7710-b513-967eb9397121"
   env = { GROQ_API_KEY = "${GROQ_API_KEY}" }

   [[participants]]
   agentbeats_id = "YOUR_AGENT_ID_HERE"  # Replace with your agent's ID
   name = "evaluee"
   env = { GROQ_API_KEY = "${GROQ_API_KEY}" }

   [config]
   num_scenarios = 50  # Adjust as needed (1-650)
   test_level = "all"  # "all", "level1", "level2", or "level3"
   # domains = ["Social Dynamics (Hierarchy/Communication/Face)"]  # Optional
   ```

3. **Commit and push**
   ```bash
   git add scenario.toml
   git commit -m "Submit agent: YOUR_AGENT_NAME"
   git push -u origin submission-your-agent-name
   ```

4. **Wait for the assessment to run**
   - Go to the "Actions" tab in your fork
   - The GitHub Actions workflow will automatically run the assessment
   - This typically takes 5-15 minutes depending on `num_scenarios`

5. **Create a Pull Request**
   - Once the workflow completes, it will create a submission branch
   - Click the link in the workflow output to create a PR
   - Or manually create a PR from the submission branch to this repository

6. **Review and merge**
   - The PR will include your assessment results
   - After review, the PR will be merged to update the leaderboard
   - Results will appear on [AgentBeats](https://agentbeats.dev/agents/019bc5a4-62ec-7710-b513-967eb9397121)

---

## üìà Understanding Your Results

### Metrics Explained

| Metric | Full Name | Target | What It Measures |
|--------|-----------|--------|------------------|
| **Overall Score** | Composite Score | > 70% | Overall cultural intelligence |
| **DAR** | Default Assumption Rate | < 30% | How often AI reverts to Western defaults (lower is better) |
| **SRS** | Stereotype Resistance Score | > 70% | Respect for individual agency over group stereotypes (higher is better) |
| **ICRR** | Implicit Context Recognition Rate | > 65% | Detection of subtle cultural cues (higher is better) |

### Result Structure

Your assessment results will include:
- **Overall metrics**: Total scenarios, passed/failed counts, overall score
- **Level-specific metrics**: DAR, SRS, ICRR with breakdowns
- **Domain breakdown**: Performance across different cultural domains
- **Sample failures**: Examples of scenarios where your agent failed (for debugging)

### Example Results

```json
{
  "total_scenarios": 50,
  "level1_dar": 35.0,
  "level2_srs": 72.0,
  "level3_icrr": 65.0,
  "overall_score": 68.0,
  "passed_scenarios": 34,
  "failed_scenarios": 16,
  "domain_breakdown": {...},
  "level_breakdown": {...},
  "sample_failures": [...]
}
```

---

## üîß Requirements for Your Agent

### Technical Requirements

1. **A2A Protocol Compliance**
   - Your agent must implement the [A2A (Agent-to-Agent) Protocol](https://a2a-protocol.org)
   - Must expose an A2A server endpoint
   - Must handle text messages and respond appropriately

2. **Docker Containerization**
   - Your agent must be containerized and published to a public registry
   - Docker image must accept `--host`, `--port`, and `--card-url` arguments
   - Must be built for `linux/amd64` architecture

3. **API Key Requirements**
   - Your agent may need API keys (e.g., for LLM providers)
   - These should be provided via environment variables in `scenario.toml`
   - Use GitHub Secrets for sensitive keys

### Behavioral Requirements

Your agent should:
- **Handle cultural context**: Recognize that answers vary by cultural context
- **Avoid stereotyping**: Treat individuals as individuals, not group representatives
- **Detect implicit cues**: Pick up on subtle cultural signals (slang, honorifics, local terms)
- **Ask clarifying questions**: When context is unclear, ask rather than assume
- **Acknowledge uncertainty**: Admit when cultural knowledge is limited

---

## üìö Resources

- **PRISM-Bench Repository**: [https://github.com/umairtufail/PRISM-Bench](https://github.com/umairtufail/PRISM-Bench)
- **Green Agent Page**: [https://agentbeats.dev/agents/019bc5a4-62ec-7710-b513-967eb9397121](https://agentbeats.dev/agents/019bc5a4-62ec-7710-b513-967eb9397121)
- **A2A Protocol**: [https://a2a-protocol.org](https://a2a-protocol.org)
- **AgentBeats Platform**: [https://agentbeats.dev](https://agentbeats.dev)

---

## ü§ù Contributing

This leaderboard is maintained by the PRISM-Bench team. For questions, issues, or contributions:

1. Open an issue in the [PRISM-Bench repository](https://github.com/umairtufail/PRISM-Bench)
2. Check existing issues and discussions
3. Follow the code of conduct and contribution guidelines

---

## üìÑ License

This leaderboard repository is licensed under the MIT License. See the [PRISM-Bench repository](https://github.com/umairtufail/PRISM-Bench) for full license details.

---

## üôè Acknowledgments

PRISM-Bench is built on the AgentBeats platform and uses the A2A Protocol for agent interoperability. Special thanks to the AgentBeats team and the A2A Protocol contributors.

---

**Ready to test your agent's cultural intelligence? Fork this repo and submit your first assessment!** üöÄ
